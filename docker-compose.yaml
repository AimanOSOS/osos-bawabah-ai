services:
  server:
    build:
      context: .
      dockerfile: app/Dockerfile
      args:
        USE_CUDA: "true"  # Enable CUDA build
      # Enable BuildKit for better caching
      cache_from:
        - bawabah-ai:latest
    ports:
      - 6060:6060
    # Add volume for Hugging Face cache to persist between builds
    volumes:
      - huggingface_cache:/home/appuser/.cache/huggingface
    # GPU support configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1  # Use 1 GPU (you can change to 2 for both GPUs)
              capabilities: [gpu]
          memory: "8G" # <-- This line was moved
    environment:
      - CUDA_VISIBLE_DEVICES=0  # Use GPU 0 (change to 1 for GPU 1, or 0,1 for both)
      - NVIDIA_VISIBLE_DEVICES=0
      - CUDA_MEMORY_FRACTION=0.3
      - PYTHONUNBUFFERED=1

volumes:
  huggingface_cache:
